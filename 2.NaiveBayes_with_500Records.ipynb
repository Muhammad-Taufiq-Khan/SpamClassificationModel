{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "increasing-recorder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>martin a posted tassos papadopoulos the greek ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>man threatens explosion in moscow thursday aug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>klez the virus that won t die already the most...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in adding cream to spaghetti carbonara which ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               email  label\n",
       "0   date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...      0\n",
       "1  martin a posted tassos papadopoulos the greek ...      0\n",
       "2  man threatens explosion in moscow thursday aug...      0\n",
       "3  klez the virus that won t die already the most...      0\n",
       "4   in adding cream to spaghetti carbonara which ...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df =  pd.read_csv(\"spam_or_not_spam.csv\")\n",
    "#Read the CSV file for training\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "weighted-failing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.174000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.379489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label\n",
       "count  500.000000\n",
       "mean     0.174000\n",
       "std      0.379489\n",
       "min      0.000000\n",
       "25%      0.000000\n",
       "50%      0.000000\n",
       "75%      0.000000\n",
       "max      1.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(n=500, random_state = 300 ).reset_index(drop = True)\n",
    "#there was 3K emails , we took 500 mail and droped rest of all.\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adopted-deployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "Label = df.iloc[:,1]\n",
    "#column 1 is our label\n",
    "\n",
    "Feature = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "decent-tourist",
   "metadata": {},
   "outputs": [],
   "source": [
    "                ##### CLEANING #####\n",
    "    \n",
    "from nltk.corpus import stopwords #remove stopwords from text\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "Lemmatizer = WordNetLemmatizer() #Object of WordNetLemmatizer class\n",
    "import re #Remove irreguler expression\n",
    "\n",
    "l = len(df)\n",
    "for i in range(l):\n",
    "    mail = re.sub(\"[^a-zA-Z]\",\" \",df[\"email\"][i])  #Remove all charecter without alphabet from email[i] & store in var mail\n",
    "    mail = mail.lower() #convert each word into lower case\n",
    "    word_tokens = mail.split() # split each word separated by space and store on var word_tokens\n",
    "    \n",
    "    clean_word_tokens= [Lemmatizer.lemmatize(word) for word in word_tokens if word not in stopwords.words('english')] # Convert Non stopword token into Lemma\n",
    "    cleaned_mail = \" \".join(clean_word_tokens) #join each clean_word_tokens with space \n",
    "    Feature.append(cleaned_mail)  \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-entertainment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "nearby-think",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        ### VECTORIZATION ###\n",
    "    \n",
    "from sklearn.feature_extraction.text import CountVectorizer #Convert a list into vector form according to frequency\n",
    "cv = CountVectorizer() #Object of CountVectorizer class\n",
    "\n",
    "feature_vector = cv.fit_transform(Feature).toarray()  #Converting 'Feature' into vector by  'fit_transform' function()\n",
    "feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "desperate-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "        #### SPLITING DATASET INTO TRAIN AND VALIDATION SET#####\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_feature, testing_feature, training_label, testing_label = train_test_split(feature_vector,Label, test_size = .33, random_state  = 50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "macro-marathon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "model = MultinomialNB()\n",
    "#model = svm.SVC()\n",
    "\n",
    "        ##### Training the Model ###\n",
    "model.fit(training_feature, training_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "molecular-vitamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation##\n",
    "predicted = model.predict(testing_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "detected-grass",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9696969696969697"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy#\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "Accuracy = accuracy_score(testing_label, predicted)\n",
    "Accuracy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "written-password",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[135,   2],\n",
       "       [  3,  25]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = confusion_matrix(testing_label, predicted)\n",
    "conf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}